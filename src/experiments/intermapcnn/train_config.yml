# configuration file
# use this configuration if no command line arguments are passed

##########
# dataset
##########
data_path: data/training/llps_vs_non_llps_train.csv
sqn_column: Sequence
label_column: Label

##########
# model
##########
img_size: 320
n_layer: 1
n_head: 4
feedforward_dim: 1280

##########
# configuration
##########
resume_training: False
seed: 1
epochs: 4
batch_size: 64
lr: 0.0001
# DROPOUT applies to the multi-head self attetion layer and cross attention layer
# after the language model
dropout: 0.2
weight_decay: 0


##########
# output
##########
checkpoint_path: checkpoints/trained_models/intermapcnn_baseline_h4_l1.pth
